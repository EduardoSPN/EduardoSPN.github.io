<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Trading Up</title>
    <meta charset="utf-8" />
    <meta name="author" content="Eduardo Schiappa-Pietra" />
    <link rel="stylesheet" href="slides.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Trading Up
## Task 1 - Merging
### Eduardo Schiappa-Pietra
### 8/22/2020

---




class: inverse, center, middle
# Reading in and subsetting infoUSA
### See Previous report
---

---
class: inverse, center, middle
# Reading in and subsetting Corelogic data 
## SQL Query
---

### Reading in and subsetting the data

**Load Packages**

```r
rm(list = ls())

library(tidyverse)
library(purrr)
library(furrr)
library(R.utils)

library(data.table)
library(R.utils) #Required for fread() to read compressed files
library(vroom)
library(parallel)
library(multidplyr)


library(dtplyr)
library(feather)
library(rlist)

#To work with SQL tables
library(RODBC)
library(odbc)
library(DBI)
library(sqldf)
library(RSQLite)
library(dbplyr)

#Set as WD wherever this Rscript is stored in
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
getwd()
```
---
### Reading in and subsetting the Corelogic data

We inspect the var names of the dataset and we read in a small sample of infoUSA (for an initial merge)

```r
###########################
##### INITIAL STUFF #######
###########################

# Inspect variable names in Corelogic
core_logic_mtg_vars &lt;- read.csv(file = "//oit-nas-fe11.oit.duke.edu/corelogic/data/raw/UniversityofPA_DeedWithMtgs_AKZA_6KPKSN_12.txt", 
                                header = TRUE, sep = "|", nrows = 2) %&gt;% colnames() %&gt;% tolower() %&gt;% str_sort()

#Small dataset - One zip_code and one year for initial merging
infousa_nc_small &lt;- fread("data/infousa_NC_small.txt")

#InfoUSA var_names
infousa_small_vars &lt;- colnames(infousa_nc_small)
```
---
### Reading in and subsetting the Corelogic data

Set up the ODBC connection to the SQL database (finally on the VM) and run query. We extract only the first 5 digits of the zip, me format the date variables
and filter only resale transactions, owner occupied status and NC.

```r
###########################################
##### READ IN CORELOGIC DATA  - SQL #######
###########################################

# Check Drivers and pick relevant one
unique(odbcListDrivers())

# Set up connection to ODBC and SQL data base
con_2 &lt;- dbConnect(odbc(),
                   Driver = "MySQL ODBC 8.0 Unicode Driver",
                   Server = "corelogic-sql.ssri.duke.edu",
                   Database = "corelogic_flat",
                   UID = "corelogic",
                   PWD = "said-aplomb 8%[hypo] pucker[seem]")


# Query (I guess we could parallelize this
time_query &lt;- system.time({
  cor_sql_nc &lt;- dbGetQuery(con_2,
                             "SELECT fips AS fips_c, apn_unformatted AS apn_unformatted_c, pcl_id_iris_frmtd AS pcl_id_iris_frmtd_c, 
                             apn_sequence_number AS apn_sequence_number_c, pending_record_indicator AS pending_record_indicator_c, 
                             corporate_indicator AS corporate_indicator_c, owner_1_last_name AS last_name_1_c, owner_1_first_name_and_mi AS first_name_1_c,
                             owner_2_last_name AS last_name_2_c, owner_2_first_name_and_mi AS first_name_2_c,
                             owner_etal_indicator AS owner_etal_indicator_c, owner_relationship_type AS owner_relationship_type_c, 
                             situs_house_number_prefix AS house_number_prefix_c, situs_house_number_suffix AS house_number_suffix_c,
                             situs_house_number AS house_number_c, situs_street_direction AS street_direction_c, situs_street_name AS street_name_c, 
                             situs_mode AS mode_c, situs_quadrant AS quadrant_c, situs_apartment_unit AS unit_number_c,
                             situs_city AS city_c, situs_state AS state_c, 
                             
                             LEFT(situs_zip_code, 5) AS zip_c, FORMAT(sale_date, 'yyyyMMdd') AS sale_date_c,
                             FORMAT(recording_date, 'yyyyMMdd') AS recording_date_c, 
                             
                             transaction_type AS transaction_type_c,
                             absentee_owner_status AS absentee_owner_status_c
                             
                             FROM deeds_with_mortgages
                             
                             WHERE situs_state = 'NC'
                             AND transaction_type = 1
                             AND absentee_owner_status='S';"
  )
  
})


# Close connection
dbDisconnect(con)

fwrite(cor_sql_nc, "data/corelogic_NC_sql.txt")
```
---

### Reading in and subsetting the Corelogic data


```r
#####################
##### INSPECT #######
#####################

#Read in data
core_nc &lt;- fread("data/corelogic_NC_sql.txt")

#Inspect
class(core_nc)
colnames(core_nc)

#Convert into DT
core_nc &lt;- as.data.table(core_nc)

#Check var types
core_nc %&gt;% map(class)

#Check dates
head(core_nc$sale_date_c, 50)
tail(core_nc$sale_date_c, 50)
```
---
class: inverse, center, middle
# Merging InfoUSA and Corelogic
---

### Merging

The different var names between the datasets will be useful for the SQL Inner Join. To merge in R using data tables we actually need the same names of the key variables.

Here are the number of observations for each data set. Makes sense?


Dataset           |    Numb of Obs        Numb of Vars
------------------|-----------------|-----------------
InfoUSA           |    27,121,986   |63
Corelogic         |    1,991,222    |27
Corelogic w/ corp |    1,941,339    |27  

---
### Merging

Read in Data

```r
###############################################
##### READ IN INFOUSA AND CORELOGIC DATA ######
###############################################

# InfoUSA
time_fread_infousa_parallel &lt;- system.time({
  cores &lt;- detectCores()
  c1 &lt;- makeCluster(cores)
  clusterEvalQ(c1, library(data.table))
  
  infousa_nc &lt;- fread("data/infousa_NC.txt")
  
  stopCluster(c1)
})

head(infousa_nc, 10)
class(infousa_nc)

#InfoUSA - Small
infousa_nc_small &lt;- vroom("data/infousa_NC_small.csv")

#Corelogic
core_nc &lt;- fread("data/corelogic_NC_sql.txt")

#Corelogic  - Small
core_nc_small &lt;- vroom("data/corelogic_NC_small.csv")
```

---
### Merging

Trying SQL Join - Not enough memory

```r
########################
##### MERGE - SQL ######
########################

### Not enough memory (even in the VM) ###

# Create a new in-memory SQL database with the data from NC and use SQL functions to merge
con_local &lt;- dbConnect(RSQLite::SQLite(), dbname = ":memory:")
copy_to(con_local, infousa_nc, "infousa_nc_small")
copy_to(con_local, core_nc, "core_nc_small")
dbListTables(con_local)


# # Merge 1- SQL
# time_merge_sql &lt;- system.time({
#   merge_1 &lt;- dbGetQuery(con_local,
#                         "SELECT *
#                             FROM core_nc_small
#                             INNER JOIN infousa_nc_small
#                             ON last_name_1=owner_1_last_name
#                             AND first_name_1 = owner_1_first_name_and_mi
#                             AND zip = situs_zip_code
#                             AND house_num = situs_house_number
#                             AND street_name = situs_street_name;")
# })
# 
# dbDisconnect(con_local)
```

---
### Merging

We try a regular data table merge. Works but I get a warning that I'm about to run out of memory. 
First we need some adjustments


```r
########################
##### MERGE - DT #######
########################

### Come adjustments first ####

# Check col names
colnames(core_nc)
colnames(infousa_nc)

# Index for the columns which names need to change
change_index &lt;-  match(c("first_name_1", "last_name_1", "ZIP", "STREET_NAME", "HOUSE_NUM"), colnames(infousa_nc))

# Change var names for the merge in InfoUSA
colnames(infousa_nc)[change_index] &lt;- c("first_name_1_c", "last_name_1_c", "zip_c", "street_name_c", "house_number_c")

# We also need the same variable types
class(infousa_nc$first_name_1_c)
class(core_nc$first_name_1_c)

class(infousa_nc$last_name_1_c)
class(core_nc$last_name_1_c)

class(infousa_nc$zip_c)
class(core_nc$zip_c)

class(infousa_nc$street_name_c)
class(core_nc$street_name_c)  

class(infousa_nc$house_number_c)
class(core_nc$house_number_c)  

# We need to put house_number_c as character in corelogic
core_nc[,house_number_c := as.character(house_number_c )]

# Now lets create a temporary ID in Corelogic to keep track of the merges
core_nc$temp_id &lt;- seq(nrow(core_nc))
```

---
### Merging

A first merge attempt. Need to inspect variables in detail to find inconsistencies and try to make homogeneous. For instance: different lenght of characters in 'house_number"


```r
##### 1st MERGE #######

# Merge by: Owner first name,  Owner last name, zipcode, address name and address number
attempt_1 &lt;- merge(core_nc, infousa_nc, by = c("first_name_1_c", "last_name_1_c", "zip_c", "street_name_c", "house_number_c"))

colnames(attempt_1)
head(attempt_1)

#attempt &lt;- attempt[-which(duplicated(attempt$X)),] 

paste('percentage merged:', 100*(length(unique(attempt_1$temp_id))/length(unique(core_nc$temp_id))))

# Get rid of corporate owners
core_nc_2 &lt;- core_nc[- which(corporate_indicator_c == 'Y')]

##### 2nd MERGE #######

# iterate!
```

---

class: inverse, center, middle
# TO DO
---

* Check key variables in merge and try to harmonize them between the two datasets. For example, the variable "house_number" has three digits in InfoUSA and 4 in Corelogic. Maybe we are looking for house_number_prefix or suffix?

* Check for duplicates. Maybe create an additional ID to index the combined data

* Try different iterations for the merging and replicate Sarah's matching approach.

* Strategy to clean complicated character variables like addresses

* Look for inconsistencies for further cleaning
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
